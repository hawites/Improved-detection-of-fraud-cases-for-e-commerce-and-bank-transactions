# Improved Detection of Fraud Cases for E-commerce and Bank Transactions

## ğŸ“ Project Overview
This project addresses the critical challenge of fraud detection using two datasets:
- **E-commerce fraud data**
- **Credit card transaction data**

Our goal is to build reliable machine learning models to detect fraud, apply explainability, and interpret the key drivers behind fraudulent activity.

---

## âœ… Task 1: Data Cleaning, Preprocessing & Feature Engineering

### âœ… Activities Completed:
- Loaded all datasets and confirmed absence of missing values.
- Converted time columns to `datetime64` format.
- Removed 1,081 duplicates from credit card data.
- Converted `ip_address` to integer and merged with geolocation data.
- Performed univariate and bivariate analysis:
  - Class imbalance observed in both datasets.
- Created key engineered features:
  - `time_since_signup`, `hour_of_day`, `day_of_week`, transaction count per user and device.
- Used **SMOTE** to oversample minority class.

### ğŸ” Visuals:
- Class distribution plots for e-commerce and credit card datasets.

---

## âœ… Task 2: Model Training & Evaluation

### âœ… Modeling Steps:
- Encoded categorical variables using OneHotEncoding.
- Used SMOTE for handling imbalance.
- Split data into train/test using stratified sampling.

### âœ… Models Trained:
1. **Logistic Regression** â€“ Baseline model
2. **XGBoost Classifier** â€“ Chosen ensemble model

### ğŸ“Š Evaluation Metrics:
- **Precision-Recall Curve (AUC-PR)**
- **F1-Score**
- **Confusion Matrix**

### ğŸ¯ Results:
| Dataset       | Model                | F1 Score | AUC-PR |
|---------------|----------------------|----------|--------|
| E-commerce    | Logistic Regression  | 0.61     | 0.67   |
| E-commerce    | XGBoost              | 0.69     | 0.71   |
| Credit Card   | Logistic Regression  | 0.09     | 0.72   |
| Credit Card   | XGBoost              | 0.77     | 0.78   |

ğŸ“Œ **Best Model**: XGBoost (both datasets)

---

## âœ… Task 3: Model Explainability (SHAP)

### ğŸ§  SHAP Visualizations:
- **Summary Plot**: Global feature importance.
- **Force Plot**: Local explanation for a single prediction.

### ğŸ” Key Drivers Identified:
- `transaction_count`, `hour_of_day`, and `device_transaction_count` were among top influential features in predicting fraud.

---

## ğŸ—‚ Project Structure

â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ Fraud_Data.csv
â”‚ â”œâ”€â”€ creditcard.csv
â”‚ â””â”€â”€ IpAddress_to_Country.csv
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”œâ”€â”€ features.py
â”‚ â”œâ”€â”€ models.py
â”‚ â””â”€â”€ shap_explainer.py
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ EDA_and_Preprocessing.ipynb
â”‚ â”œâ”€â”€ Model_Training.ipynb
â”‚ â””â”€â”€ SHAP_Explainability.ipynb
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_preprocessing.py
â”‚ â”œâ”€â”€ test_features.py
â”‚ â””â”€â”€ test_shap_explainer.py
â”œâ”€â”€ scripts/
â”‚ â””â”€â”€ run_training.py
â””â”€â”€ .github/
â””â”€â”€ workflows/
â””â”€â”€ main.yml

---

## âœ… Tech Stack

- Python, Pandas, Scikit-learn, XGBoost, SHAP
- Imbalanced-learn (SMOTE)
- Matplotlib for visualizations
- Modular OOP Codebase for maintainability

---

## âœ… Authors
Hawi T.  
Submission Date: August 4, 2025